#!/bin/bash

# Can't use `-e`, or it's not possible to "catch" errors after they fire up
set +e

##
# testing toolset is the first thing to check for
# TODO testodo <<<"tool to report tests pending to write"
testools=(tested teskip)

for tool in ${testools[@]}; do source "bash/$tool.bash"; done

report="$( for tool in ${testools[@]}; do ${tool}--test || exit; done )" || {
  echo "###################################"
  echo "- - - check bash errors above - - -"
  echo "             = = = = =             "
  echo "     TEST TOOLS CHECKUP FAILED     "
  echo "             = = = = =             "
	echo "- - - check test report below - - -"
  echo "###################################"
	echo "$report"
  echo "###################################"
  echo "Sorry, can't run test suite because 'testools' checkup failed"
	exit 1
}

# TODO Could be better checking for test filenames based on code filenames?
# TODO for example, list bash/*.bash and check every lib file has tests
# TODO it would ease pending test identify
#test $(find test/bash -name "bashlib-*" | wc -l) -gt 0
#tested "there are at least 1 bash test"
#find test/bash -name "bashlib-*" -exec './{}' \;

run_tests_for () {
	local prefix="${1:?"$FUNCNAME: argument must be specified (prefix)"}"

	# TODO iterating over an array of filenames is a "bash-bad-practice"
	# TODO i should use `find` with `-exec` action instead
  testfiles=("$(ls test/bash/${prefix}-*)")

	test "${#testfiles[@]}" -gt "0" ;tested "There is at least 1 $prefix test"

	for file in ${testfiles[@]}; do
		# TODO content convention tests
		# ex: `grep "[ ;]tested[ ]" test/bash/bashlib-assert-code`
		#   to seek tested calls and check the code style for them
		# TODO generate stats to calculate progress Â¿or even introspection?
		# ex: `grep -c "[ ;]tested[ ]" test/bash/bashlib-assert-code`
		#   to count the minimum expected times that `tested` should be called

		echo -en "> Running test '$(basename "$file")'...\n  " # pad reports
		("./$file") &>/dev/null # hide both output streams
		tested "running $file in a subshell returns 0" # test $? -eq 0 implicit
		# running in a subshell avoids env pollution and unexpected exits

		# TODO measure the time spent by each test
		# TODO dot animation while running?
		# TODO progress could be `echo .` for each tested call?
		# TODO both outs were hidden because working with a test fail implies isolating
		# TODO interactively allow developer at this tty (if it's a tty) to do so?
		# TODO maybe save report=$(./$file) and print it if failed?
	done
	tested "All '$prefix' test scripts pass running in a subshell"
}

##
# bash lib tests are the next thing to check. iai cmds depend on it
# TODO WTF are abc.bash tests? stop cowboy coding PLEASE!
# TODO WTF are abc-call_trace.bash tests? stop cowboy coding PLEASE!
# TODO rename bashlib to bashido
run_tests_for "bashlib"

##
# next procede with iai cmd tests, iai interactive cli depends on it
run_tests_for "iaicmd"

# TODO iai interactive commands (expecting developer interaction)

cat <<TODOS >&2
TODOs at file '${BASH_SOURCE[0]}':
#2 tool to write todos like this one
  - 'testodo' seems a nice name
  - seems easy to implement but
  WRITE TESTS FIRST with diff_test
  - stop fucking cowboy coding
  - use caller to get filename and signal a "workinghere" msg
  ##
  # Extra tests for better _developer experience_
  # TODO test that utilities ease debugging
  # - 'diff_test' utility wraps lines within vertical bars
  # - 'tested' utility outputs call trace
  # TODO test that utilities ease developing
  # - each source file ends with vim modeline
#4 Integrate a code coverage tool, i.e. https://simonkagstrom.github.io/kcov/
TODOS

echo -e "#################\n KEEP WORKING ON \n#################"


cat <<DONE
######################
! All tests were run !
######################
              good job :D

Now continue with TDD and write more test scripts.
Don't enter cowboy coding mode please!
DONE

##
# vim modeline
# /* vim: set filetype=sh ts=2 shiftwidth=2: */
